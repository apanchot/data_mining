{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dycPE3iCytg"
   },
   "source": [
    "# Data Mining Project\n",
    "\n",
    "* Alex Panchot (M20190546)\n",
    "* Hugo Mentzingen (M20190215)\n",
    "* Rennan Valadares (M20190146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GilsiSUBBwr4"
   },
   "outputs": [],
   "source": [
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.svm import LinearSVR\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRPEY--YFQZJ"
   },
   "outputs": [],
   "source": [
    "#Global variables\n",
    "env_params = {\n",
    "    \"Outliers\" : [655,5084,7195,5882,8261,171,5293,8866,9149,7961,5293,5211,6835],\n",
    "    \"NoisyData\" : [9294], #First Policy´s Year = 53784.0\n",
    "    \"InsConColumns\" : ['Premiums in LOB: Motor',\n",
    "                       'Premiums in LOB: Household',\n",
    "                       'Premiums in LOB: Health',\n",
    "                       'Premiums in LOB:  Life',\n",
    "                       'Premiums in LOB: Work Compensations',\n",
    "                       'Premium: Sum'],\n",
    "    \"ValEngColumns\" : ['Educational Degree',\n",
    "                       'Geographic Living Area',\n",
    "                       'Has Children (Y=1)',\n",
    "                       'First Policy´s Year',\n",
    "                       'Gross Monthly Salary',\n",
    "                       'Customer Monetary Value',\n",
    "                       'Claims Rate',\n",
    "                       'Age',\n",
    "                       'First Policy´s Age'],\n",
    "    \"CategoricalColumns\" : ['Educational Degree',\n",
    "                            'Geographic Living Area',\n",
    "                            'Has Children (Y=1)'],\n",
    "    \"NumericalColumns\" : ['Customer Identity',\n",
    "                          'First Policy´s Year',\n",
    "                          'Gross Monthly Salary',\n",
    "                          'Customer Monetary Value',\n",
    "                          'Claims Rate',\n",
    "                          'Premiums in LOB: Motor',\n",
    "                          'Premiums in LOB: Household',\n",
    "                          'Premiums in LOB: Health',\n",
    "                          'Premiums in LOB:  Life',\n",
    "                          'Premiums in LOB: Work Compensations',\n",
    "                          'Age',\n",
    "                          'First Policy´s Age',\n",
    "                          'Premium: Sum']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z64jR3B9G-iU"
   },
   "outputs": [],
   "source": [
    "#Function to split the DataFrame in data complete and incomplete\n",
    "#The rows that belong to the 'incomplete' dataframe have at least one NaN\n",
    "def split(data_insurance, reset_index = False):\n",
    "    data_insurance_complete = pd.DataFrame()\n",
    "    data_insurance_incomplete = data_insurance[data_insurance.isna().any(axis=1)]\n",
    "    if reset_index:\n",
    "        data_insurance_incomplete.reset_index(inplace=True)\n",
    "        data_insurance_incomplete.drop('index', axis=1, inplace=True)\n",
    "    data_insurance_complete = data_insurance[~data_insurance.isna().any(axis=1)]\n",
    "    return data_insurance_complete, data_insurance_incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbB4cIQ2HUqe"
   },
   "outputs": [],
   "source": [
    "#Function to plot the correlation between variables\n",
    "def plotCorrelation(df):\n",
    "\n",
    "    sns.set()\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    sns.heatmap(df.corr(method='pearson'), annot=True, fmt='.2f', vmin=-1, vmax=1, linewidths=.9, ax = ax).set_title('Variables correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6fvdk55OSud"
   },
   "outputs": [],
   "source": [
    "#Function to separate the dataframe into 'Insurance Consumption' and 'Value & Engagement' features\n",
    "def separateVariables(df):\n",
    "    InsCon = df[InsConColumns]\n",
    "    ValEng = df[ValEngColumns]\n",
    "\n",
    "    return InsCon, ValEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dpb4HGyWHlb8"
   },
   "outputs": [],
   "source": [
    "#Function to rescale or normalize the dataframe columns\n",
    "def rescale_and_normalize(data_insurance):\n",
    "    \n",
    "    data_insurance_ = deepcopy(data_insurance)\n",
    "    data_insurance_.drop(env_params['Outliers'], inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data_insurance = scaler.fit_transform(data_insurance_)\n",
    "    scaled_data_insurance = pd.DataFrame(scaled_data_insurance, columns = data_insurance_.columns)\n",
    "    \n",
    "    return scaled_data_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sX4-ZMqbIDAa"
   },
   "outputs": [],
   "source": [
    "#Function to evaluate the best n_neighbors to use with KNN\n",
    "def evaluate_classifier(data_insurance):\n",
    "    data_insurance_complete, data_insurance_incomplete = split(data_insurance, reset_index=True)\n",
    "\n",
    "    def create_and_fit_classifier(k):\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)    \n",
    "        incomplete = deepcopy(data_insurance_incomplete)\n",
    "        complete = deepcopy(data_insurance_complete)   \n",
    "        X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != value].values,\n",
    "                                                            complete.loc[:,value].values, test_size = 0.2, random_state = 0)\n",
    "        trained_model = clf.fit(X_train, y_train)\n",
    "        result = [clf, y_test, X_test, trained_model, incomplete, complete]\n",
    "        return result\n",
    "    \n",
    "    accuracies_for_value_dict = {}\n",
    "\n",
    "    for index, value in enumerate(env_params['CategoricalColumns']):\n",
    "\n",
    "        accuracy_dict = {}\n",
    "\n",
    "        for k in range(3,100):\n",
    "\n",
    "            result = create_and_fit_classifier(k)\n",
    "            clf = result[0]\n",
    "            y_test = result[1]\n",
    "            X_test = result[2]                                                \n",
    "            \n",
    "            #calculate the model accuracy and storing the value into a dictionary\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_matrix = confusion_matrix(y_test, y_pred)\n",
    "            accuracy = accuracy_matrix.trace()/accuracy_matrix.sum()\n",
    "            accuracy_dict[k] = accuracy\n",
    "        \n",
    "        accuracies_for_value_dict[value] = accuracy_dict\n",
    "    \n",
    "    return accuracies_for_value_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mAZboFplIdD5"
   },
   "outputs": [],
   "source": [
    "#Function that uses KNN to classify the missing values on CATEGORICAL columns\n",
    "def classify_categorical_data(data_insurance):\n",
    "    data_insurance_complete, data_insurance_incomplete = split(data_insurance, reset_index=True)\n",
    "  \n",
    "    #Creating a classifier to fill the categorical data: Educational Degree, Geographic Living Area and Has Children (Y=1)\n",
    "    for index, value in enumerate(env_params['CategoricalColumns']):\n",
    "\n",
    "        clf = KNeighborsClassifier(n_neighbors=5)    \n",
    "        \n",
    "        incomplete = deepcopy(data_insurance_incomplete)\n",
    "        complete = deepcopy(data_insurance_complete)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != value].values,\n",
    "                                                            complete.loc[:,value].values, test_size = 0.2, random_state = 0)\n",
    "        \n",
    "        trained_model = clf.fit(X_train, \n",
    "                                 y_train)\n",
    "           \n",
    "        #fill the numerical columns with the column mean\n",
    "        incomplete.loc[:, ~incomplete.columns.isin(env_params['CategoricalColumns']) ] = incomplete.loc[:, \n",
    "                                ~incomplete.columns.isin(env_params['CategoricalColumns'])].apply(lambda column: column.fillna(column.mean()), axis=0)\n",
    "        \n",
    "        #Round Age and First Policy's Year\n",
    "        incomplete['Age'] = incomplete['Age'].apply(lambda x:round(x))\n",
    "        incomplete['First Policy´s Year'] =  incomplete['First Policy´s Year'].apply(lambda x:round(x))\n",
    "                \n",
    "        #Categorical columns with the exception of the one we want to predict\n",
    "        cat_without_the_column = deepcopy(env_params['CategoricalColumns'])\n",
    "        cat_without_the_column.pop(index)\n",
    "        \n",
    "        #Fill the categorical columns with the exception of the one we want to predict with the mode\n",
    "        #(Hugo) Here I corrected the function to dataframe.mode instead of .mean\n",
    "        incomplete.loc[:, incomplete.columns.isin(cat_without_the_column) ] = incomplete.loc[:, \n",
    "                        incomplete.columns.isin(cat_without_the_column)].apply(lambda column: column.fillna(int(column.mode())), axis=0)\n",
    "              \n",
    "        prediction = trained_model.predict(incomplete.loc[:,incomplete.columns != value])\n",
    "        temp_df = pd.DataFrame(prediction.reshape(-1,1), columns = [value])\n",
    "        \n",
    "        \n",
    "        #now we are filling data_insurance_incomplete \n",
    "        for ind in range(len(temp_df)):\n",
    "            if np.isnan(data_insurance_incomplete[value][ind]):\n",
    "                data_insurance_incomplete[value][ind] = temp_df[value][ind]\n",
    "\n",
    "\n",
    "    #and reconstructing the original dataframe\n",
    "    dataset = pd.concat([data_insurance_complete, data_insurance_incomplete])\n",
    "    dataset.set_index(dataset['Customer Identity'] - 1, inplace=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB_kdFOdIko_"
   },
   "outputs": [],
   "source": [
    "#funcion for checking which algorithm is the best for using on each column for NUMERICAL columns\n",
    "def checking_choices(data_insurance, number_of_tests=10):\n",
    "    data_insurance_complete, data_insurance_incomplete = split(data_insurance)\n",
    "\n",
    "    choices = []\n",
    "    better_for_each_column = []\n",
    "    \n",
    "    #testing\n",
    "    for i in range(number_of_tests):\n",
    "        choices.append(regressor_test(data_insurance))\n",
    "    \n",
    "    #chosing the best algorithm for each column\n",
    "    for i in range(len(data_insurance.columns)):\n",
    "        l = []\n",
    "        for j in range(len(choices)):\n",
    "            l.append(choices[j][i])\n",
    "        better_for_each_column.append(max(set(l), key = l.count))\n",
    "        \n",
    "    return better_for_each_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pX12xS__IwNE"
   },
   "outputs": [],
   "source": [
    "#function for test which regressor is best for each numerical column\n",
    "#Return a list of lists with the best algorithm for each test (choose the number of tests on checking_choices function )\n",
    "def regressor_test(data_insurance):\n",
    "#variables to hold the Mean Squared Errors for each model\n",
    "    kn_errors = []\n",
    "    linear_errors = []\n",
    "    svr_errors = []    \n",
    "    \n",
    "    complete,incomplete = split(data_insurance)\n",
    "    \n",
    "    for i in complete.columns:\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != i].values,\n",
    "                                                            complete.loc[:,i].values, test_size = 0.2, random_state = 0)\n",
    "        \n",
    "        regressor1 = KNeighborsRegressor(5, \n",
    "                                       weights ='distance', \n",
    "                                       metric = 'euclidean')\n",
    "        regressor2= LinearRegression()\n",
    "        regressor3=LinearSVR()\n",
    "        \n",
    "        \n",
    "        KN_trained_model1 = regressor1.fit(X_train, \n",
    "                                 y_train)\n",
    "        Linear_trained_model2 = regressor2.fit(X_train, \n",
    "                                 y_train)\n",
    "        SVR_trained_model3 = regressor3.fit(X_train, \n",
    "                                 y_train)  \n",
    "        \n",
    "        incomplete_2 = deepcopy(incomplete)\n",
    "        incomplete_2.loc[:, incomplete.columns != i] = incomplete_2.loc[:, \n",
    "                                incomplete.columns != i].apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "\n",
    "        y_pred1 = regressor1.predict(X_test)\n",
    "        y_pred2 = regressor2.predict(X_test)\n",
    "        y_pred3 = regressor3.predict(X_test)\n",
    "        \n",
    "        \n",
    "        kn_errors.append(math.sqrt(mean_squared_error(y_test, y_pred1)))\n",
    "        linear_errors.append(math.sqrt(mean_squared_error(y_test, y_pred2)))\n",
    "        svr_errors.append(math.sqrt(mean_squared_error(y_test, y_pred3)))\n",
    "        \n",
    "        \n",
    "    #ROOT MEAN SQUARED ERROR \n",
    "    RMSE= []\n",
    "\n",
    "    #Filling RMSE for each column\n",
    "    for i in range(0, len(complete.columns)):\n",
    "        l = []\n",
    "        l.extend((kn_errors[i], linear_errors[i], svr_errors[i]))\n",
    "        \n",
    "        if min(l) == kn_errors[i]:\n",
    "            RMSE.append(\"KNN\")\n",
    "        elif min(l) == linear_errors[i]:\n",
    "            RMSE.append(\"Linear\")\n",
    "        elif min(l) == svr_errors[i]:\n",
    "            RMSE.append(\"SVR\")\n",
    "    \n",
    "\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RamXoklKI5uR"
   },
   "outputs": [],
   "source": [
    "#function to apply the regressors\n",
    "def apply_regressors(choices, data_insurance, numerical_columns):\n",
    "\n",
    "    complete,incomplete = split(data_insurance)\n",
    "\n",
    "    for i,v in enumerate(complete.columns):\n",
    "        \n",
    "        #Check if it is a numerical column\n",
    "        if v in numerical_columns:\n",
    "            \n",
    "            #use the choosen algorithm \n",
    "            if choices[i] == 'KNN':\n",
    "                regressor = KNeighborsRegressor(5, \n",
    "                                                weights ='distance', \n",
    "                                                metric = 'euclidean')\n",
    "            elif choices[i] == 'SVR':\n",
    "                regressor = LinearSVR()\n",
    "                \n",
    "            elif choices[i] == 'Linear':\n",
    "                regressor = LinearRegression()\n",
    "                \n",
    "            #Split in train-test data    \n",
    "            X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != v].values,\n",
    "                                                                complete.loc[:,v].values, test_size = 0.2, random_state = 0)\n",
    "            #Train the model\n",
    "            trained_model = regressor.fit(X_train, \n",
    "                                     y_train)\n",
    "            \n",
    "            #Make predictions\n",
    "            incomplete_2 = deepcopy(incomplete)\n",
    "            incomplete_2.loc[:, incomplete.columns != v] = incomplete_2.loc[:, \n",
    "                                    incomplete.columns != v].apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "            \n",
    "            prediction = trained_model.predict(incomplete_2.loc[:,incomplete_2.columns != v])\n",
    "            temp_df = pd.DataFrame(prediction.reshape(-1,1), columns = [v])\n",
    "            \n",
    "            #fill NaN's on data_arrivals_incomplete \n",
    "            for index in range(len(temp_df)):\n",
    "                if np.isnan(incomplete.iloc[index,i]):\n",
    "                    incomplete.iloc[index,i] = temp_df[v][index]\n",
    "\n",
    "\n",
    "\n",
    "    #and filling the nan's on arrivals_df\n",
    "    dataset = pd.concat([complete, incomplete])\n",
    "    dataset.set_index(dataset['Customer Identity'] - 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsuhl9-0JBJo"
   },
   "outputs": [],
   "source": [
    "#_________________________Cleaning and Filling the Data with the algorithms___________________________________________\n",
    "\n",
    "#Read the dataset\n",
    "insurance_df = pd.read_csv('https://raw.githubusercontent.com/apanchot/data_mining/master/A2Z_Insurance.csv?token=ANHK7VCNE3LUXISDBRLXCM252CMEK')\n",
    "\n",
    "#Create Age column\n",
    "insurance_df['Age'] = insurance_df.loc[:, 'Brithday Year'].apply(lambda x : 2019 - x )\n",
    "\n",
    "#Create First Policy´s Age column\n",
    "insurance_df['First Policy´s Age'] = insurance_df.loc[:, 'First Policy´s Year'].apply(lambda x : 2019 - x )\n",
    "\n",
    "#Drop Birthday Year and Customer Id\n",
    "insurance_df.drop(['Brithday Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdT2awcbJQTF"
   },
   "outputs": [],
   "source": [
    "#Drop rows with more than 3 NaN's\n",
    "insurance_df.dropna(thresh=(len(insurance_df.columns) - 3), inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "u4OuIGlriGbo",
    "outputId": "3e21fb23-4347-4377-cc55-7b171b74287b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1994"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting the rows with 'First Policy´s Age' > 'Age'\n",
    "insurance_df[insurance_df['First Policy´s Age'] > insurance_df['Age']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5HJUJnSal23I",
    "outputId": "a205ac92-e832-46fe-f8fe-c0316a87c88f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.08 %\n"
     ]
    }
   ],
   "source": [
    "#Proportion of customers below 21 that have children\n",
    "x = insurance_df[(insurance_df['Age'] <= 21) & (insurance_df['Has Children (Y=1)'] == 1)].shape[0]\n",
    "y = insurance_df[(insurance_df['Age'] <= 21) & (insurance_df['Has Children (Y=1)'] == 0)].shape[0]\n",
    "print(\"{:.2f}\".format(x/(x+y)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnhOMZ5AJf2P"
   },
   "outputs": [],
   "source": [
    "data_insurance = deepcopy(insurance_df)\n",
    "\n",
    "#Dropping one evident wrong value in the dataframe\n",
    "data_insurance.drop(env_params['NoisyData'], inplace=True)\n",
    "\n",
    "#Encoding Educational Degree and returning back the NaN's\n",
    "data_insurance['Educational Degree'] = data_insurance['Educational Degree'].apply(str)\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "\n",
    "data_insurance.loc[:,'Educational Degree'] = labelencoder_X.fit_transform(data_insurance.loc[:,'Educational Degree'])\n",
    "\n",
    "data_insurance['Educational Degree'] = data_insurance['Educational Degree'].apply(lambda x : np.nan if x == 4 else x )\n",
    "\n",
    "#Adding the sum of all premiums pais as a column \n",
    "plot_data_insurance['Premium: Sum']=plot_data_insurance[['Premiums in LOB: Work Compensations',\n",
    "                                                         'Premiums in LOB:  Life',\n",
    "                                                         'Premiums in LOB: Health',\n",
    "                                                         'Premiums in LOB: Household',\n",
    "                                                         'Premiums in LOB: Motor']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tb5WVbNWJvbE"
   },
   "outputs": [],
   "source": [
    "#Verify the optimal n_neighbors to our KNN classifiers\n",
    "scaled_data_insurance = rescale_and_normalize(data_insurance)\n",
    "scaled_data_insurance = scaled_data_insurance.drop(columns='Customer Identity')\n",
    "\n",
    "accuracies_for_column_dict = evaluate_classifier(scaled_data_insurance)\n",
    "fig, ax = plt.subplots(3, figsize=(15,5))\n",
    "fig.suptitle('KNN - Accuracy x n_neighbors')\n",
    "ax[0].plot(list(accuracies_for_column_dict['Educational Degree'].keys()),\n",
    "                                    list(accuracies_for_column_dict['Educational Degree'].values()),\n",
    "                                    'bx-') \n",
    "ax[0].set_title('Educational Degree')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(list(accuracies_for_column_dict['Geographic Living Area'].keys()),\n",
    "                                    list(accuracies_for_column_dict['Geographic Living Area'].values()),\n",
    "                                    'bx-') \n",
    "ax[1].set_title('Geographic Living Area')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[2].plot(list(accuracies_for_column_dict['Has Children (Y=1)'].keys()),\n",
    "                                    list(accuracies_for_column_dict['Has Children (Y=1)'].values()),\n",
    "                                    'bx-') \n",
    "ax[2].set_title('Has Children (Y=1)')\n",
    "ax[2].grid(True)\n",
    "\n",
    "for ax in ax.flat:\n",
    "    ax.set(xlabel='n_neighbors', ylabel='Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bbp9HDl8J2AJ"
   },
   "outputs": [],
   "source": [
    "#Preparing to plot correlation\n",
    "plot_data_insurance = deepcopy(data_insurance)\n",
    "plot_data_insurance.drop(columns='Customer Identity', inplace=True)\n",
    "plot_data_insurance.drop(env_params['Outliers'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZroJNJDTJ_zz"
   },
   "outputs": [],
   "source": [
    "#Plotting the correlation between all variables\n",
    "plotCorrelation(plot_data_insurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01OSFvy9KMXj"
   },
   "outputs": [],
   "source": [
    "#Fill categorical data with the KNN predicted Values\n",
    "data_insurance = classify_categorical_data(data_insurance, env_params['CategoricalColumns'])\n",
    "\n",
    "#Fill numerical data with the best regressor algorithm\n",
    "data_insurance = apply_regressors(checking_choices(data_insurance),data_insurance, numerical_columns)\n",
    "\n",
    "\n",
    "#Full dataset\n",
    "data_insurance.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5AOXUApKYps"
   },
   "outputs": [],
   "source": [
    "#_________________________Checking the distributions, correlations and outliers___________________________________________\n",
    "\n",
    "#Age x Premiuns\n",
    "# 7195 is an outlier or wrong filling for age.\n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(data_insurance[['Age',\n",
    "                             'Premiums in LOB: Motor',\n",
    "                             'Premiums in LOB: Household',\n",
    "                             'Premiums in LOB: Health',\n",
    "                             'Premiums in LOB:  Life',\n",
    "                             'Premiums in LOB: Work Compensations']],\n",
    "            diag_kind='hist',\n",
    "            kind='scatter',\n",
    "            palette=\"husl\",\n",
    "           plot_kws = {'alpha': 0.6,\n",
    "                      's': 20,\n",
    "                      'edgecolor':'k'},\n",
    "           height=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nN0ZZEP9KxfV"
   },
   "outputs": [],
   "source": [
    "#Education x Premiums\n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(data_insurance[['Educational Degree',\n",
    "                             'Premiums in LOB: Motor',\n",
    "                             'Premiums in LOB: Household',\n",
    "                             'Premiums in LOB: Health',\n",
    "                             'Premiums in LOB:  Life',\n",
    "                             'Premiums in LOB: Work Compensations']],\n",
    "            diag_kind='hist',\n",
    "            kind='scatter',\n",
    "            palette=\"husl\",\n",
    "           plot_kws = {'alpha': 0.6,\n",
    "                      's': 20,\n",
    "                      'edgecolor':'k'},\n",
    "           height=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NOec-cDLciJ"
   },
   "outputs": [],
   "source": [
    "#Gross Monthly x Premiums\n",
    "#Here we can see 2 outliers on GMS index 5882 and 8261 \n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(data_insurance[['Gross Monthly Salary',\n",
    "                             'Premiums in LOB: Motor',\n",
    "                             'Premiums in LOB: Household',\n",
    "                             'Premiums in LOB: Health',\n",
    "                             'Premiums in LOB:  Life',\n",
    "                             'Premiums in LOB: Work Compensations']],\n",
    "            diag_kind='hist',\n",
    "            kind='scatter',\n",
    "            palette=\"husl\",\n",
    "           plot_kws = {'alpha': 0.6,\n",
    "                      's': 20,\n",
    "                      'edgecolor':'k'},\n",
    "           height=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8rlePLKLkBs"
   },
   "outputs": [],
   "source": [
    "#CMV x Premiuns\n",
    "#Here we can see 1 outlier on GMS index 171\n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(data_insurance[['Customer Monetary Value',\n",
    "                             'Premiums in LOB: Motor',\n",
    "                             'Premiums in LOB: Household',\n",
    "                             'Premiums in LOB: Health',\n",
    "                             'Premiums in LOB:  Life',\n",
    "                             'Premiums in LOB: Work Compensations']],\n",
    "            diag_kind='hist',\n",
    "            kind='scatter',\n",
    "            palette=\"husl\",\n",
    "           plot_kws = {'alpha': 0.6,\n",
    "                      's': 20,\n",
    "                      'edgecolor':'k'},\n",
    "           height=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EETg6oqPLxd5"
   },
   "outputs": [],
   "source": [
    "#Claims Rate x Premiuns\n",
    "#Again the 171 is an outlier for Claim Rate, since its the opposite of CMV\n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(data_insurance[['Claims Rate',\n",
    "                             'Premiums in LOB: Motor',\n",
    "                             'Premiums in LOB: Household',\n",
    "                             'Premiums in LOB: Health',\n",
    "                             'Premiums in LOB:  Life',\n",
    "                             'Premiums in LOB: Work Compensations']],\n",
    "            diag_kind='hist',\n",
    "            kind='scatter',\n",
    "            palette=\"husl\",\n",
    "           plot_kws = {'alpha': 0.6,\n",
    "                      's': 20,\n",
    "                      'edgecolor':'k'},\n",
    "           height=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc_DfGWHL9bd"
   },
   "outputs": [],
   "source": [
    "#Just Premiums\n",
    "#We have to check each of this outliers\n",
    "# 5293 for Motor\n",
    "# 8866 for Household\n",
    "# 9149 for Health\n",
    "# 7961 and 7988 for Work Compensation\n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(data_insurance[['Premiums in LOB: Motor',\n",
    "                             'Premiums in LOB: Household',\n",
    "                             'Premiums in LOB: Health',\n",
    "                             'Premiums in LOB:  Life',\n",
    "                             'Premiums in LOB: Work Compensations']],\n",
    "            diag_kind='hist',\n",
    "            kind='scatter',\n",
    "            palette=\"husl\",\n",
    "           plot_kws = {'alpha': 0.6,\n",
    "                      's': 20,\n",
    "                      'edgecolor':'k'},\n",
    "           height=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0RjAFoUMVI-"
   },
   "outputs": [],
   "source": [
    "#_________________________Encoding the data ___________________________________________________________________\n",
    "#Saving the column names\n",
    "columns_list = ['Basic','High School', 'BSc/MSc','PhD','Area 1','Area 2','Area 3','Area 4','No Kids','Have Kids']\n",
    "for i in insurance_df.columns:\n",
    "    if i not in env_params['CategoricalColumns']:\n",
    "        columns_list.append(i)\n",
    "\n",
    "#Should we use dummy variables on educational degree ? My opinion is Yes !\n",
    "onehotencoder = OneHotEncoder(categorical_features = [2,4,5])\n",
    "encoded_data = pd.DataFrame(onehotencoder.fit_transform(data_insurance).toarray())\n",
    "\n",
    "#Give the column names back\n",
    "encoded_data.columns = columns_list\n",
    "\n",
    "#Drop identity not needed anymore\n",
    "encoded_data.drop('Customer Identity', axis=1, inplace=True)\n",
    "columns_list.remove('Customer Identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2esYRfwJMedI"
   },
   "outputs": [],
   "source": [
    "#_________________________Standadizing the data ___________________________________________________________________\n",
    "\n",
    "#Should we standardize or normalize the data ? (depends on which ML algorithm we will use)\n",
    "# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Scaling \n",
    "scaled_df = scaler.fit_transform(encoded_data.loc[:,'First Policy´s Year':])\n",
    "scaled_df = pd.DataFrame(scaled_df)\n",
    "\n",
    "scaled_data = pd.concat([encoded_data.loc[:,:'Customer Identity'],scaled_df], axis=1)  \n",
    "\n",
    "scaled_data.columns = columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_insurance.groupby(['Educational Degree','Geographic Living Area','Has Children (Y=1)'])['Customer Monetary Value'].mean().sort_values(ascending=False)\n",
    "\n",
    "data_insurance.groupby(['Geographic Living Area','Educational Degree','Has Children (Y=1)'])['Customer Monetary Value'].mean().sort_values(ascending=False)\n",
    "\n",
    "data_insurance.groupby(['Has Children (Y=1)','Educational Degree','Geographic Living Area'])['Customer Monetary Value'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_data['Premium: Sum']=encoded_data[['Premiums in LOB: Work Compensations','Premiums in LOB:  Life','Premiums in LOB: Health','Premiums in LOB: Household','Premiums in LOB: Motor']].sum(axis=1)\n",
    "\n",
    "#cluster_binned=data_insurance.loc[:,['Educational Degree','Geographic Living Area', 'Has Children (Y=1)','Premium Sum Binned', 'Gross Monthly Salary Binned','Age Binned', 'Claims Rate Binned']]\n",
    "cluster_binned=encoded_data.iloc[:,[0,1,2,3,4,5,6,7,8,9,11,13,19,20,12]]\n",
    "cluster_binned.drop([5692,8013,167,638,9354,658,8870,8597,5122,5041,6621,7722,167,690,890,9354,50,133,738,110,770,954,924,995,6864,6489,10220],inplace=True)\n",
    "data=pd.DataFrame(preprocessing.minmax_scale(cluster_binned))\n",
    "#data=cluster_binned\n",
    "data.columns=encoded_data.columns[[0,1,2,3,4,5,6,7,8,9,11,13,19,20,12]]\n",
    "data.iloc[:,0:10]=encoded_data.iloc[:,0:10]\n",
    "\n",
    "ncl=4\n",
    "centroids,labels,_=k_means(data,n_clusters=ncl,n_init=50,max_iter=200,n_jobs=-1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "j=1\n",
    "yl=data.columns[j]\n",
    "#plt.show()\n",
    "#plt.ylabel()\n",
    "#plt.xlabel(data.columns[-1])\n",
    "for i in range(ncl):\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,4])\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,5])\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,6])\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,7])\n",
    "    \n",
    "plt.plot(centroids[:,-1],centroids[:,j],'sg',markersize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_binned=encoded_data.iloc[:,[11,13,19,20,12]]\n",
    "cluster_binned.drop([5692,8013,167,638,9354,658,8870,8597,5122,5041,6621,7722,167,690,890,9354,50,133,738,110,770,954,924,995,6864,6489,10220],inplace=True)\n",
    "\n",
    "data=pd.DataFrame(preprocessing.minmax_scale(cluster_binned))\n",
    "data.columns=encoded_data.columns[[11,13,19,20,12]]\n",
    "ncl=6\n",
    "centroids,labels,_=k_means(data,n_clusters=ncl,n_init=50,max_iter=200,n_jobs=-1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "j=0\n",
    "for i in range(ncl):\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,j])\n",
    "plt.plot(centroids[:,-1],centroids[:,j],'sg',markersize=10)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "j=1\n",
    "for i in range(ncl):\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,j])\n",
    "plt.plot(centroids[:,-1],centroids[:,j],'sg',markersize=10)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "j=2\n",
    "for i in range(ncl):\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,j])\n",
    "plt.plot(centroids[:,-1],centroids[:,j],'sg',markersize=10)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "j=3\n",
    "for i in range(ncl):\n",
    "    plt.scatter(data.iloc[labels==i,-1],data.iloc[labels==i,j])\n",
    "plt.plot(centroids[:,-1],centroids[:,j],'sg',markersize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cluster_binned=encoded_data.iloc[:,[0,1,2,3,4,5,6,7,8,9,11,13,19,20,12]]\n",
    "cluster_binned.drop([5692,8013,167,638,9354,658,8870,8597,5122,5041,6621,7722,167,690,890,9354,50,133,738,110,770,954,924,995,6864,6489,10220],inplace=True)\n",
    "data=pd.DataFrame(preprocessing.minmax_scale(cluster_binned))\n",
    "#data=cluster_binned\n",
    "data.columns=encoded_data.columns[[0,1,2,3,4,5,6,7,8,9,11,13,19,20,12]]\n",
    "data.iloc[:,0:10]=encoded_data.iloc[:,0:10]\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "regr = LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
    "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
    "     random_state=0, tol=1e-05, verbose=0)\n",
    "\n",
    "regr.fit(data.iloc[:8000,:-5], data.iloc[:8000,-2]) \n",
    "regr.score(data.iloc[8000:,:-5], data.iloc[8000:,-2])\n",
    "regr.coef_\n",
    "regr.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "premiums=deepcopy(insurance_df)\n",
    "premiums.drop([9294],inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "#plt.ylim(-2000,1000)\n",
    "plt.scatter(2019-premiums[\"First Policy´s Year\"],premiums['Customer Monetary Value'])\n",
    "\n",
    "\n",
    "premiums['Premium Sum']=premiums[['Premiums in LOB: Work Compensations','Premiums in LOB:  Life','Premiums in LOB: Health','Premiums in LOB: Household','Premiums in LOB: Motor']].sum(axis=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Mining Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
