{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Mining Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dycPE3iCytg",
        "colab_type": "text"
      },
      "source": [
        "# Data Mining Project\n",
        "\n",
        "* Alex Panchot (M20190546)\n",
        "* Hugo Mentzingen (M20190215)\n",
        "* Rennan Valadares (M20190146)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GilsiSUBBwr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Imports\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "from sklearn.svm import LinearSVR\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRPEY--YFQZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Global variables\n",
        "env_params = {\n",
        "    \"Outliers\" : [655,5084,7195,5882,8261,171,5293,8866,9149,7961,5293,5211,6835],\n",
        "    \"NoisyData\" : [9294], #First Policy´s Year = 53784.0\n",
        "    \"InsConColumns\" : ['Premiums in LOB: Motor',\n",
        "                       'Premiums in LOB: Household',\n",
        "                       'Premiums in LOB: Health',\n",
        "                       'Premiums in LOB:  Life',\n",
        "                       'Premiums in LOB: Work Compensations',\n",
        "                       'Premium: Sum'],\n",
        "    \"ValEngColumns\" : ['Educational Degree',\n",
        "                       'Geographic Living Area',\n",
        "                       'Has Children (Y=1)',\n",
        "                       'First Policy´s Year',\n",
        "                       'Gross Monthly Salary',\n",
        "                       'Customer Monetary Value',\n",
        "                       'Claims Rate',\n",
        "                       'Age',\n",
        "                       'First Policy´s Age'],\n",
        "    \"CategoricalColumns\" : ['Educational Degree',\n",
        "                            'Geographic Living Area',\n",
        "                            'Has Children (Y=1)'],\n",
        "    \"NumericalColumns\" : ['Customer Identity',\n",
        "                          'First Policy´s Year',\n",
        "                          'Gross Monthly Salary',\n",
        "                          'Customer Monetary Value',\n",
        "                          'Claims Rate',\n",
        "                          'Premiums in LOB: Motor',\n",
        "                          'Premiums in LOB: Household',\n",
        "                          'Premiums in LOB: Health',\n",
        "                          'Premiums in LOB:  Life',\n",
        "                          'Premiums in LOB: Work Compensations',\n",
        "                          'Age',\n",
        "                          'First Policy´s Age',\n",
        "                          'Premium: Sum']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z64jR3B9G-iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to split the DataFrame in data complete and incomplete\n",
        "#The rows that belong to the 'incomplete' dataframe have at least one NaN\n",
        "def split(data_insurance, reset_index = False):\n",
        "    data_insurance_complete = pd.DataFrame()\n",
        "    data_insurance_incomplete = data_insurance[data_insurance.isna().any(axis=1)]\n",
        "    if reset_index:\n",
        "        data_insurance_incomplete.reset_index(inplace=True)\n",
        "        data_insurance_incomplete.drop('index', axis=1, inplace=True)\n",
        "    data_insurance_complete = data_insurance[~data_insurance.isna().any(axis=1)]\n",
        "    return data_insurance_complete, data_insurance_incomplete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbB4cIQ2HUqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to plot the correlation between variables\n",
        "def plotCorrelation(df):\n",
        "\n",
        "    sns.set()\n",
        "    fig, ax = plt.subplots(figsize=(15,10))\n",
        "    sns.heatmap(df.corr(method='pearson'), annot=True, fmt='.2f', vmin=-1, vmax=1, linewidths=.9, ax = ax).set_title('Variables correlation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6fvdk55OSud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to separate the dataframe into 'Insurance Consumption' and 'Value & Engagement' features\n",
        "def separateVariables(df):\n",
        "    InsCon = df[InsConColumns]\n",
        "    ValEng = df[ValEngColumns]\n",
        "\n",
        "    return InsCon, ValEng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpb4HGyWHlb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to rescale or normalize the dataframe columns\n",
        "def rescale_and_normalize(data_insurance):\n",
        "    \n",
        "    data_insurance_ = deepcopy(data_insurance)\n",
        "    data_insurance_.drop(env_params['Outliers'], inplace=True)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data_insurance = scaler.fit_transform(data_insurance_)\n",
        "    scaled_data_insurance = pd.DataFrame(scaled_data_insurance, columns = data_insurance_.columns)\n",
        "    \n",
        "    return scaled_data_insurance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX4-ZMqbIDAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to evaluate the best n_neighbors to use with KNN\n",
        "def evaluate_classifier(data_insurance):\n",
        "    data_insurance_complete, data_insurance_incomplete = split(data_insurance, reset_index=True)\n",
        "\n",
        "    def create_and_fit_classifier(k):\n",
        "        clf = KNeighborsClassifier(n_neighbors=k)    \n",
        "        incomplete = deepcopy(data_insurance_incomplete)\n",
        "        complete = deepcopy(data_insurance_complete)   \n",
        "        X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != value].values,\n",
        "                                                            complete.loc[:,value].values, test_size = 0.2, random_state = 0)\n",
        "        trained_model = clf.fit(X_train, y_train)\n",
        "        result = [clf, y_test, X_test, trained_model, incomplete, complete]\n",
        "        return result\n",
        "    \n",
        "    accuracies_for_value_dict = {}\n",
        "\n",
        "    for index, value in enumerate(env_params['CategoricalColumns']):\n",
        "\n",
        "        accuracy_dict = {}\n",
        "\n",
        "        for k in range(3,100):\n",
        "\n",
        "            result = create_and_fit_classifier(k)\n",
        "            clf = result[0]\n",
        "            y_test = result[1]\n",
        "            X_test = result[2]                                                \n",
        "            \n",
        "            #calculate the model accuracy and storing the value into a dictionary\n",
        "            y_pred = clf.predict(X_test)\n",
        "            accuracy_matrix = confusion_matrix(y_test, y_pred)\n",
        "            accuracy = accuracy_matrix.trace()/accuracy_matrix.sum()\n",
        "            accuracy_dict[k] = accuracy\n",
        "        \n",
        "        accuracies_for_value_dict[value] = accuracy_dict\n",
        "    \n",
        "    return accuracies_for_value_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAZboFplIdD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function that uses KNN to classify the missing values on CATEGORICAL columns\n",
        "def classify_categorical_data(data_insurance):\n",
        "    data_insurance_complete, data_insurance_incomplete = split(data_insurance, reset_index=True)\n",
        "  \n",
        "    #Creating a classifier to fill the categorical data: Educational Degree, Geographic Living Area and Has Children (Y=1)\n",
        "    for index, value in enumerate(env_params['CategoricalColumns']):\n",
        "\n",
        "        clf = KNeighborsClassifier(n_neighbors=5)    \n",
        "        \n",
        "        incomplete = deepcopy(data_insurance_incomplete)\n",
        "        complete = deepcopy(data_insurance_complete)\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != value].values,\n",
        "                                                            complete.loc[:,value].values, test_size = 0.2, random_state = 0)\n",
        "        \n",
        "        trained_model = clf.fit(X_train, \n",
        "                                 y_train)\n",
        "           \n",
        "        #fill the numerical columns with the column mean\n",
        "        incomplete.loc[:, ~incomplete.columns.isin(env_params['CategoricalColumns']) ] = incomplete.loc[:, \n",
        "                                ~incomplete.columns.isin(env_params['CategoricalColumns'])].apply(lambda column: column.fillna(column.mean()), axis=0)\n",
        "        \n",
        "        #Round Age and First Policy's Year\n",
        "        incomplete['Age'] = incomplete['Age'].apply(lambda x:round(x))\n",
        "        incomplete['First Policy´s Year'] =  incomplete['First Policy´s Year'].apply(lambda x:round(x))\n",
        "                \n",
        "        #Categorical columns with the exception of the one we want to predict\n",
        "        cat_without_the_column = deepcopy(env_params['CategoricalColumns'])\n",
        "        cat_without_the_column.pop(index)\n",
        "        \n",
        "        #Fill the categorical columns with the exception of the one we want to predict with the mode\n",
        "        #(Hugo) Here I corrected the function to dataframe.mode instead of .mean\n",
        "        incomplete.loc[:, incomplete.columns.isin(cat_without_the_column) ] = incomplete.loc[:, \n",
        "                        incomplete.columns.isin(cat_without_the_column)].apply(lambda column: column.fillna(int(column.mode())), axis=0)\n",
        "              \n",
        "        prediction = trained_model.predict(incomplete.loc[:,incomplete.columns != value])\n",
        "        temp_df = pd.DataFrame(prediction.reshape(-1,1), columns = [value])\n",
        "        \n",
        "        \n",
        "        #now we are filling data_insurance_incomplete \n",
        "        for ind in range(len(temp_df)):\n",
        "            if np.isnan(data_insurance_incomplete[value][ind]):\n",
        "                data_insurance_incomplete[value][ind] = temp_df[value][ind]\n",
        "\n",
        "\n",
        "    #and reconstructing the original dataframe\n",
        "    dataset = pd.concat([data_insurance_complete, data_insurance_incomplete])\n",
        "    dataset.set_index(dataset['Customer Identity'] - 1, inplace=True)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB_kdFOdIko_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#funcion for checking which algorithm is the best for using on each column for NUMERICAL columns\n",
        "def checking_choices(data_insurance, number_of_tests=10):\n",
        "    data_insurance_complete, data_insurance_incomplete = split(data_insurance)\n",
        "\n",
        "    choices = []\n",
        "    better_for_each_column = []\n",
        "    \n",
        "    #testing\n",
        "    for i in range(number_of_tests):\n",
        "        choices.append(regressor_test(data_insurance))\n",
        "    \n",
        "    #chosing the best algorithm for each column\n",
        "    for i in range(len(data_insurance.columns)):\n",
        "        l = []\n",
        "        for j in range(len(choices)):\n",
        "            l.append(choices[j][i])\n",
        "        better_for_each_column.append(max(set(l), key = l.count))\n",
        "        \n",
        "    return better_for_each_column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX12xS__IwNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function for test which regressor is best for each numerical column\n",
        "#Return a list of lists with the best algorithm for each test (choose the number of tests on checking_choices function )\n",
        "def regressor_test(data_insurance):\n",
        "#variables to hold the Mean Squared Errors for each model\n",
        "    kn_errors = []\n",
        "    linear_errors = []\n",
        "    svr_errors = []    \n",
        "    \n",
        "    complete,incomplete = split(data_insurance)\n",
        "    \n",
        "    for i in complete.columns:\n",
        "            \n",
        "        X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != i].values,\n",
        "                                                            complete.loc[:,i].values, test_size = 0.2, random_state = 0)\n",
        "        \n",
        "        regressor1 = KNeighborsRegressor(5, \n",
        "                                       weights ='distance', \n",
        "                                       metric = 'euclidean')\n",
        "        regressor2= LinearRegression()\n",
        "        regressor3=LinearSVR()\n",
        "        \n",
        "        \n",
        "        KN_trained_model1 = regressor1.fit(X_train, \n",
        "                                 y_train)\n",
        "        Linear_trained_model2 = regressor2.fit(X_train, \n",
        "                                 y_train)\n",
        "        SVR_trained_model3 = regressor3.fit(X_train, \n",
        "                                 y_train)  \n",
        "        \n",
        "        incomplete_2 = deepcopy(incomplete)\n",
        "        incomplete_2.loc[:, incomplete.columns != i] = incomplete_2.loc[:, \n",
        "                                incomplete.columns != i].apply(lambda row: row.fillna(row.mean()), axis=1)\n",
        "\n",
        "        y_pred1 = regressor1.predict(X_test)\n",
        "        y_pred2 = regressor2.predict(X_test)\n",
        "        y_pred3 = regressor3.predict(X_test)\n",
        "        \n",
        "        \n",
        "        kn_errors.append(math.sqrt(mean_squared_error(y_test, y_pred1)))\n",
        "        linear_errors.append(math.sqrt(mean_squared_error(y_test, y_pred2)))\n",
        "        svr_errors.append(math.sqrt(mean_squared_error(y_test, y_pred3)))\n",
        "        \n",
        "        \n",
        "    #ROOT MEAN SQUARED ERROR \n",
        "    RMSE= []\n",
        "\n",
        "    #Filling RMSE for each column\n",
        "    for i in range(0, len(complete.columns)):\n",
        "        l = []\n",
        "        l.extend((kn_errors[i], linear_errors[i], svr_errors[i]))\n",
        "        \n",
        "        if min(l) == kn_errors[i]:\n",
        "            RMSE.append(\"KNN\")\n",
        "        elif min(l) == linear_errors[i]:\n",
        "            RMSE.append(\"Linear\")\n",
        "        elif min(l) == svr_errors[i]:\n",
        "            RMSE.append(\"SVR\")\n",
        "    \n",
        "\n",
        "\n",
        "    return RMSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RamXoklKI5uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to apply the regressors\n",
        "def apply_regressors(choices, data_insurance, numerical_columns):\n",
        "\n",
        "    complete,incomplete = split(data_insurance)\n",
        "\n",
        "    for i,v in enumerate(complete.columns):\n",
        "        \n",
        "        #Check if it is a numerical column\n",
        "        if v in numerical_columns:\n",
        "            \n",
        "            #use the choosen algorithm \n",
        "            if choices[i] == 'KNN':\n",
        "                regressor = KNeighborsRegressor(5, \n",
        "                                                weights ='distance', \n",
        "                                                metric = 'euclidean')\n",
        "            elif choices[i] == 'SVR':\n",
        "                regressor = LinearSVR()\n",
        "                \n",
        "            elif choices[i] == 'Linear':\n",
        "                regressor = LinearRegression()\n",
        "                \n",
        "            #Split in train-test data    \n",
        "            X_train, X_test, y_train, y_test = train_test_split(complete.loc[:,complete.columns != v].values,\n",
        "                                                                complete.loc[:,v].values, test_size = 0.2, random_state = 0)\n",
        "            #Train the model\n",
        "            trained_model = regressor.fit(X_train, \n",
        "                                     y_train)\n",
        "            \n",
        "            #Make predictions\n",
        "            incomplete_2 = deepcopy(incomplete)\n",
        "            incomplete_2.loc[:, incomplete.columns != v] = incomplete_2.loc[:, \n",
        "                                    incomplete.columns != v].apply(lambda row: row.fillna(row.mean()), axis=1)\n",
        "            \n",
        "            prediction = trained_model.predict(incomplete_2.loc[:,incomplete_2.columns != v])\n",
        "            temp_df = pd.DataFrame(prediction.reshape(-1,1), columns = [v])\n",
        "            \n",
        "            #fill NaN's on data_arrivals_incomplete \n",
        "            for index in range(len(temp_df)):\n",
        "                if np.isnan(incomplete.iloc[index,i]):\n",
        "                    incomplete.iloc[index,i] = temp_df[v][index]\n",
        "\n",
        "\n",
        "\n",
        "    #and filling the nan's on arrivals_df\n",
        "    dataset = pd.concat([complete, incomplete])\n",
        "    dataset.set_index(dataset['Customer Identity'] - 1, inplace=True)\n",
        "    \n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsuhl9-0JBJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#_________________________Cleaning and Filling the Data with the algorithms___________________________________________\n",
        "\n",
        "#Read the dataset\n",
        "insurance_df = pd.read_csv('https://raw.githubusercontent.com/apanchot/data_mining/master/A2Z_Insurance.csv?token=ANHK7VCNE3LUXISDBRLXCM252CMEK')\n",
        "\n",
        "#Create Age column\n",
        "insurance_df['Age'] = insurance_df.loc[:, 'Brithday Year'].apply(lambda x : 2019 - x )\n",
        "\n",
        "#Create First Policy´s Age column\n",
        "insurance_df['First Policy´s Age'] = insurance_df.loc[:, 'First Policy´s Year'].apply(lambda x : 2019 - x )\n",
        "\n",
        "#Drop Birthday Year and Customer Id\n",
        "insurance_df.drop(['Brithday Year'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdT2awcbJQTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop rows with more than 3 NaN's\n",
        "insurance_df.dropna(thresh=(len(insurance_df.columns) - 3), inplace=True, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4OuIGlriGbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e21fb23-4347-4377-cc55-7b171b74287b"
      },
      "source": [
        "#Counting the rows with 'First Policy´s Age' > 'Age'\n",
        "insurance_df[insurance_df['First Policy´s Age'] > insurance_df['Age']].shape[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HJUJnSal23I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a205ac92-e832-46fe-f8fe-c0316a87c88f"
      },
      "source": [
        "#Proportion of customers below 21 that have children\n",
        "x = insurance_df[(insurance_df['Age'] <= 21) & (insurance_df['Has Children (Y=1)'] == 1)].shape[0]\n",
        "y = insurance_df[(insurance_df['Age'] <= 21) & (insurance_df['Has Children (Y=1)'] == 0)].shape[0]\n",
        "print(\"{:.2f}\".format(x/(x+y)*100),'%')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.08 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnhOMZ5AJf2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_insurance = deepcopy(insurance_df)\n",
        "\n",
        "#Dropping one evident wrong value in the dataframe\n",
        "data_insurance.drop(env_params['NoisyData'], inplace=True)\n",
        "\n",
        "#Encoding Educational Degree and returning back the NaN's\n",
        "data_insurance['Educational Degree'] = data_insurance['Educational Degree'].apply(str)\n",
        "\n",
        "labelencoder_X = LabelEncoder()\n",
        "\n",
        "data_insurance.loc[:,'Educational Degree'] = labelencoder_X.fit_transform(data_insurance.loc[:,'Educational Degree'])\n",
        "\n",
        "data_insurance['Educational Degree'] = data_insurance['Educational Degree'].apply(lambda x : np.nan if x == 4 else x )\n",
        "\n",
        "#Adding the sum of all premiums pais as a column \n",
        "plot_data_insurance['Premium: Sum']=plot_data_insurance[['Premiums in LOB: Work Compensations',\n",
        "                                                         'Premiums in LOB:  Life',\n",
        "                                                         'Premiums in LOB: Health',\n",
        "                                                         'Premiums in LOB: Household',\n",
        "                                                         'Premiums in LOB: Motor']].sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb5WVbNWJvbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Verify the optimal n_neighbors to our KNN classifiers\n",
        "scaled_data_insurance = rescale_and_normalize(data_insurance)\n",
        "scaled_data_insurance = scaled_data_insurance.drop(columns='Customer Identity')\n",
        "\n",
        "accuracies_for_column_dict = evaluate_classifier(scaled_data_insurance)\n",
        "fig, ax = plt.subplots(3, figsize=(15,5))\n",
        "fig.suptitle('KNN - Accuracy x n_neighbors')\n",
        "ax[0].plot(list(accuracies_for_column_dict['Educational Degree'].keys()),\n",
        "                                    list(accuracies_for_column_dict['Educational Degree'].values()),\n",
        "                                    'bx-') \n",
        "ax[0].set_title('Educational Degree')\n",
        "ax[0].grid(True)\n",
        "\n",
        "ax[1].plot(list(accuracies_for_column_dict['Geographic Living Area'].keys()),\n",
        "                                    list(accuracies_for_column_dict['Geographic Living Area'].values()),\n",
        "                                    'bx-') \n",
        "ax[1].set_title('Geographic Living Area')\n",
        "ax[0].grid(True)\n",
        "\n",
        "ax[2].plot(list(accuracies_for_column_dict['Has Children (Y=1)'].keys()),\n",
        "                                    list(accuracies_for_column_dict['Has Children (Y=1)'].values()),\n",
        "                                    'bx-') \n",
        "ax[2].set_title('Has Children (Y=1)')\n",
        "ax[2].grid(True)\n",
        "\n",
        "for ax in ax.flat:\n",
        "    ax.set(xlabel='n_neighbors', ylabel='Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbp9HDl8J2AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preparing to plot correlation\n",
        "plot_data_insurance = deepcopy(data_insurance)\n",
        "plot_data_insurance.drop(columns='Customer Identity', inplace=True)\n",
        "plot_data_insurance.drop(env_params['Outliers'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZroJNJDTJ_zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plotting the correlation between all variables\n",
        "plotCorrelation(plot_data_insurance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01OSFvy9KMXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fill categorical data with the KNN predicted Values\n",
        "data_insurance = classify_categorical_data(data_insurance, env_params['CategoricalColumns'])\n",
        "\n",
        "#Fill numerical data with the best regressor algorithm\n",
        "data_insurance = apply_regressors(checking_choices(data_insurance),data_insurance, numerical_columns)\n",
        "\n",
        "\n",
        "#Full dataset\n",
        "data_insurance.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5AOXUApKYps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#_________________________Checking the distributions, correlations and outliers___________________________________________\n",
        "\n",
        "#Age x Premiuns\n",
        "# 7195 is an outlier or wrong filling for age.\n",
        "sns.set_style(\"ticks\")\n",
        "sns.pairplot(data_insurance[['Age',\n",
        "                             'Premiums in LOB: Motor',\n",
        "                             'Premiums in LOB: Household',\n",
        "                             'Premiums in LOB: Health',\n",
        "                             'Premiums in LOB:  Life',\n",
        "                             'Premiums in LOB: Work Compensations']],\n",
        "            diag_kind='hist',\n",
        "            kind='scatter',\n",
        "            palette=\"husl\",\n",
        "           plot_kws = {'alpha': 0.6,\n",
        "                      's': 20,\n",
        "                      'edgecolor':'k'},\n",
        "           height=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN0ZZEP9KxfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Education x Premiums\n",
        "sns.set_style(\"ticks\")\n",
        "sns.pairplot(data_insurance[['Educational Degree',\n",
        "                             'Premiums in LOB: Motor',\n",
        "                             'Premiums in LOB: Household',\n",
        "                             'Premiums in LOB: Health',\n",
        "                             'Premiums in LOB:  Life',\n",
        "                             'Premiums in LOB: Work Compensations']],\n",
        "            diag_kind='hist',\n",
        "            kind='scatter',\n",
        "            palette=\"husl\",\n",
        "           plot_kws = {'alpha': 0.6,\n",
        "                      's': 20,\n",
        "                      'edgecolor':'k'},\n",
        "           height=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NOec-cDLciJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gross Monthly x Premiums\n",
        "#Here we can see 2 outliers on GMS index 5882 and 8261 \n",
        "sns.set_style(\"ticks\")\n",
        "sns.pairplot(data_insurance[['Gross Monthly Salary',\n",
        "                             'Premiums in LOB: Motor',\n",
        "                             'Premiums in LOB: Household',\n",
        "                             'Premiums in LOB: Health',\n",
        "                             'Premiums in LOB:  Life',\n",
        "                             'Premiums in LOB: Work Compensations']],\n",
        "            diag_kind='hist',\n",
        "            kind='scatter',\n",
        "            palette=\"husl\",\n",
        "           plot_kws = {'alpha': 0.6,\n",
        "                      's': 20,\n",
        "                      'edgecolor':'k'},\n",
        "           height=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8rlePLKLkBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CMV x Premiuns\n",
        "#Here we can see 1 outlier on GMS index 171\n",
        "sns.set_style(\"ticks\")\n",
        "sns.pairplot(data_insurance[['Customer Monetary Value',\n",
        "                             'Premiums in LOB: Motor',\n",
        "                             'Premiums in LOB: Household',\n",
        "                             'Premiums in LOB: Health',\n",
        "                             'Premiums in LOB:  Life',\n",
        "                             'Premiums in LOB: Work Compensations']],\n",
        "            diag_kind='hist',\n",
        "            kind='scatter',\n",
        "            palette=\"husl\",\n",
        "           plot_kws = {'alpha': 0.6,\n",
        "                      's': 20,\n",
        "                      'edgecolor':'k'},\n",
        "           height=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EETg6oqPLxd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Claims Rate x Premiuns\n",
        "#Again the 171 is an outlier for Claim Rate, since its the opposite of CMV\n",
        "sns.set_style(\"ticks\")\n",
        "sns.pairplot(data_insurance[['Claims Rate',\n",
        "                             'Premiums in LOB: Motor',\n",
        "                             'Premiums in LOB: Household',\n",
        "                             'Premiums in LOB: Health',\n",
        "                             'Premiums in LOB:  Life',\n",
        "                             'Premiums in LOB: Work Compensations']],\n",
        "            diag_kind='hist',\n",
        "            kind='scatter',\n",
        "            palette=\"husl\",\n",
        "           plot_kws = {'alpha': 0.6,\n",
        "                      's': 20,\n",
        "                      'edgecolor':'k'},\n",
        "           height=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc_DfGWHL9bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Just Premiums\n",
        "#We have to check each of this outliers\n",
        "# 5293 for Motor\n",
        "# 8866 for Household\n",
        "# 9149 for Health\n",
        "# 7961 and 7988 for Work Compensation\n",
        "sns.set_style(\"ticks\")\n",
        "sns.pairplot(data_insurance[['Premiums in LOB: Motor',\n",
        "                             'Premiums in LOB: Household',\n",
        "                             'Premiums in LOB: Health',\n",
        "                             'Premiums in LOB:  Life',\n",
        "                             'Premiums in LOB: Work Compensations']],\n",
        "            diag_kind='hist',\n",
        "            kind='scatter',\n",
        "            palette=\"husl\",\n",
        "           plot_kws = {'alpha': 0.6,\n",
        "                      's': 20,\n",
        "                      'edgecolor':'k'},\n",
        "           height=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0RjAFoUMVI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#_________________________Encoding the data ___________________________________________________________________\n",
        "#Saving the column names\n",
        "columns_list = ['Basic','High School', 'BSc/MSc','PhD','Area 1','Area 2','Area 3','Area 4','No Kids','Have Kids']\n",
        "for i in insurance_df.columns:\n",
        "    if i not in env_params['CategoricalColumns']:\n",
        "        columns_list.append(i)\n",
        "\n",
        "#Should we use dummy variables on educational degree ? My opinion is Yes !\n",
        "onehotencoder = OneHotEncoder(categorical_features = [2,4,5])\n",
        "encoded_data = pd.DataFrame(onehotencoder.fit_transform(data_insurance).toarray())\n",
        "\n",
        "#Give the column names back\n",
        "encoded_data.columns = columns_list\n",
        "\n",
        "#Drop identity not needed anymore\n",
        "encoded_data.drop('Customer Identity', axis=1, inplace=True)\n",
        "columns_list.remove('Customer Identity')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2esYRfwJMedI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#_________________________Standadizing the data ___________________________________________________________________\n",
        "\n",
        "#Should we standardize or normalize the data ? (depends on which ML algorithm we will use)\n",
        "# Create the Scaler object\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "# Scaling \n",
        "scaled_df = scaler.fit_transform(encoded_data.loc[:,'First Policy´s Year':])\n",
        "scaled_df = pd.DataFrame(scaled_df)\n",
        "\n",
        "scaled_data = pd.concat([encoded_data.loc[:,:'Customer Identity'],scaled_df], axis=1)  \n",
        "\n",
        "scaled_data.columns = columns_list"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}